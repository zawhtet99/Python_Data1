import os
import numpy as np
import pandas as pd
import psycopg2

#find csv files in my current working directory
#isolate only the csv files
#make a new directory
#move the csv files in the new directory

#find csv files in my current working directory
csv_files = []
for file in os.listdir(os.getcwd()):
  if file.endswith('.csv'):
     csv_files.append(file)

#make a new directory
dataset_dir = 'datasets'

#create the bash command to make a new directory
# mkdir dataset_dir
try:
  mkdir = 'mkdir {0}'.format(dataset_dir)
  os.system(mkdir)
except:
  pass

#move the CSV files in the new directory
#mv filename directory
for csv in csv_files:
  mv_file = "mv '{0}' {1}".format(csv,dataset_dir)
  os.system(mv_file)
  print(mv_file)
-------------------------------
data_path = os.getcwd()+'/'+dataset_dir+'/'
df = {}
for file in csv_files:
  try:
    df[file] = pd.read_csv(data_path+file)
  except UnicodeDecodeError:
    df[file] = pd.read_csv(data_path+file, encoding="ISO-8859-1")
  print(file)
----------------------------
print(df[blabla.csv])
----------------------------------
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
#clean table names & columns
for k in csv_files:
  dataframe = df[k]
  clean_tbl_name = k.lower().replace(" ","_").replace("?","") \
  .replace("-","_").replace(r"/","_").replace("\\","_").replace("%","") \
  .replace(")","").replace(r"(","").replace("$","")

  print(clean_tbl_name)
  
  #remove .csv extension from clean_tbl_name
  tbl_name = '{0}'.format(clean_tbl_name.split('.')[0])

  print(tbl_name)

  dataframe.columns = [x.lower().replace(" ","_").replace("?","") \
        		.replace("-","_").replace(r"/","_").replace("\\","_").replace("%","") \
			.replace(")","").replace(r"(","").replace("$","") for x in dataframe.columns]
  print(dataframe.columns)

  #replacement dictionary that maps pandas dtypes to sql dtypes
  replacements = {
    'object': 'varchar',
    'float64': 'float',
    'int64': 'int',
    'datetime64': 'timestamp',
    'timedelta64[ns]': 'varchar'
  }

  #table schema
  col_str = ", ".join("{} {}".format(n,d) for (n,d) in zip(dataframe.columns,dataframe.dtypes.replace(replacements)))
  print(col_str)
------------------------------------
  #open a database connection
  host = 'database-yt.coxjbg3yl1fx.us-west-1.rds.amazonaws.com'
  dbname = 'natedb'
  user = 'nate'
  password = 'xxxx'
  conn_string = 'host=%s dbname=%s user=%s password=%s" % (host,dbname,user,password)
  conn = psycopg2.connect(conn_string)
  cursor = conn.cursor()
  print('opened database successfully')

  #drop table with same name
  cursor.execute("drop table if exists %s;" % (tbl_name))

  #create table
  cursor.execute("create table %s (%s)" % (tbl_name,col_str)
  print('{0} was created successfully'.format(tbl_name))

  conn.commit()
  conn.close()
-----------------------------------
  #insert values to table
  #save df to csv
  dataframe.to_csv(k,header=dataframe.columns,index=False,encoding='utf-8')

  #open the csv file, save it as an object
  my_file = open(k)
  print('file opened in memory')

  #upload to db
  SQL_STATEMENT = """
  COPY %s FROM STDIN WITH
    CSV
    HEADER
    DELIMITER AS ','
   """
   cursor.copy_expert(sql=SQL_STATEMENT % tbl_name, file=my_file)
   print('file copied to db')

   cursor.execute("grant select on table %s to public" % tbl_name)
   conn.commit()
   cursor.close()
   print('table {0} imported to db completed'.format(tbl_name))
  
#for loop end message
print('all tables have been successfully imported into the db')
------------------------------------------
df=pd.read_csv("Customer Contracts$.csv")
df.head()

